use_gpu: true
gpu_id: 0
worker: 0
seed: 2026
reproducibility: True

#model config
model: LightGCL
embedding_size: 64              # (int) The embedding size of users and items.
n_layers: 2                     # (int) The number of layers in LightGCL.
dropout: 0.0                    # (float) The dropout ratio.
temp: 0.8                       # (float) The temperature in softmax.
lambda1: 0.01                   # (float) The hyperparameter to control the strengths of SSL.
lambda2: 1e-05                  # (float) The L2 regularization weight.
q: 5                            # (int) A slightly overestimated rank of the adjacency matrix.

# training config
checkpoint_path: './ckptCopy/lgcl-amazonbeauty-baseline.pth'
pretrain: True
epochs: 1000
learning_rate: 1e-3
stopping_step: 20
train_batch_size: 20480
eval_batch_size: 4096000
train_neg_sample_args: 
    distribution: uniform
    sample_num: 1
    # alpha: 0.1
    dynamic: True
    candidate_num: 3
loss_decimal_place: 2

# ICPNS config
strategy: icpns
finetune: False
finetune_epochs: 1000
stopping_step_ft: 20
num_clusters: 32
popularity_alpha: 0.1
epsilon: 0.0001
cluster_method: 'kmeans'
finetune_lr: 1e-3

# evaluation config
metrics: ['Recall', 'MRR', 'NDCG', 'Precision']
eval_setting: RO_RS,full
split_ratio: [0.8, 0.1, 0.1]
topk: [10]
valid_metric: NDCG@10
eval_args:
    mode: full
metric_decimal_place: 3
eval_step: 1


# dataset config
field_separator: "\t"
seq_separator: " "
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
NEG_PREFIX: neg_
LABEL_FIELD: label
load_col:
    inter: [user_id, item_id, rating]
val_interval:
    rating: "[3,inf)"

user_inter_num_interval: "[10,inf)"
item_inter_num_interval: "[10,inf)"
